{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Melakukan import dataset standard iris dan memisahkan data dan target\n",
    "from sklearn import datasets\n",
    "iris_dataset = datasets.load_iris()\n",
    "X_iris = iris_dataset.data\n",
    "Y_iris = iris_dataset.target\n",
    "print(X_iris[0:5])\n",
    "print(Y_iris[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melakukan import dataset csv play tennis dan memisahkan data dan target\n",
    "import pandas\n",
    "ori_data_frame = pandas.read_csv('tennis.csv')\n",
    "\n",
    "# axis = 1 artinya mau drop column\n",
    "data_frame = ori_data_frame.drop('play', axis=1)\n",
    "data_frame = data_frame.select_dtypes(include=[object])\n",
    "# print(data_frame.columns)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "df_2 = data_frame.apply(le.fit_transform)\n",
    "# print(df_2)\n",
    "\n",
    "one_hot_encoder = preprocessing.OneHotEncoder()\n",
    "one_hot_encoder.fit(df_2)\n",
    "one_hot_labels = one_hot_encoder.transform(df_2).toarray()\n",
    "\n",
    "X_tennis = one_hot_labels\n",
    "Y_tennis = []\n",
    "\n",
    "for row in ori_data_frame.index:\n",
    "    Y_tennis.append(ori_data_frame['play'][row])\n",
    "\n",
    "print(X_tennis[0:5])\n",
    "print(Y_tennis[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melakukan pembelajaran full training dengan DecisionTree\n",
    "from sklearn import tree\n",
    "clf_tree = tree.DecisionTreeClassifier()\n",
    "clf_tree = clf_tree.fit(X_iris, Y_iris)\n",
    "clf_tree_2 = tree.DecisionTreeClassifier()\n",
    "clf_tree_2 = clf_tree_2.fit(X_tennis, Y_tennis)\n",
    "# Menampilkan hasil prediksi terhadap 5 instance awal\n",
    "print(clf_tree.predict(X_iris[:5]))\n",
    "print(clf_tree_2.predict(X_tennis[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menampilkan model pembelajaran tree\n",
    "data_feature_names = iris_dataset.feature_names\n",
    "data_feature_names_2 = ['outlook', 'temp', 'humidity']\n",
    "data_target_names = iris_dataset.target_names\n",
    "data_target_names_2 = ['no', 'yes']\n",
    "dot_model = tree.export_graphviz(clf_tree, feature_names = data_feature_names, class_names = data_target_names, out_file = None) \n",
    "dot_model_2 = tree.export_graphviz(clf_tree_2, class_names = data_target_names_2, out_file = None) \n",
    "\n",
    "# import graphviz\n",
    "# import os\n",
    "# os.environ[\"PATH\"] += os.pathsep + 'D:/Graphviz2.38/bin/'\n",
    "# tree_viz = graphviz.Source(dot_model) \n",
    "# tree_viz.render('tree_iris')\n",
    "# tree_viz_2 = graphviz.Source(dot_model_2) \n",
    "# tree_viz_2.render('tree_tennis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melakukan pembelajaran full training dengan MLP\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clf_mlp = MLPClassifier(solver='sgd', max_iter = 10000, alpha=1e-3, hidden_layer_sizes=(4,3))\n",
    "clf_mlp.fit(X_iris, Y_iris)\n",
    "clf_mlp_2 = MLPClassifier(solver='sgd', max_iter = 10000, alpha=1e-3, hidden_layer_sizes=(4,3))\n",
    "clf_mlp_2.fit(X_tennis, Y_tennis)\n",
    "# Menampilkan hasil prediksi terhadap 5 instance awal\n",
    "print(clf_mlp.predict(X_iris[:5]))\n",
    "print(clf_mlp_2.predict(X_tennis[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menampilkan model pembelajaran MLP untuk iris\n",
    "for i in range(0, len(clf_mlp.coefs_)):\n",
    "    print('Intercepts:')\n",
    "    print(clf_mlp.intercepts_[i])\n",
    "    print('Weights:')\n",
    "    print(clf_mlp.coefs_[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menampilkan model pembelajaran MLP untuk tennis\n",
    "for i in range(0, len(clf_mlp_2.coefs_)):\n",
    "    print('Intercepts:')\n",
    "    print(clf_mlp_2.intercepts_[i])\n",
    "    print('Weights:')\n",
    "    print(clf_mlp_2.coefs_[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melakukan import dan export model\n",
    "from sklearn.externals import joblib\n",
    "def save_model(model, filename):\n",
    "    joblib.dump(model, filename)\n",
    "    \n",
    "def load_model(filename):\n",
    "    clf = joblib.load(filename)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meng-export full training MLP dan DTree\n",
    "save_model(clf_tree, \"full_training_Tree_Iris.model\")\n",
    "save_model(clf_mlp, \"full_training_MLP_Iris.model\")\n",
    "save_model(clf_tree_2, \"full_training_Tree_Tennis.model\")\n",
    "save_model(clf_mlp_2, \"full_training_MLP_Tennis.model\")\n",
    "\n",
    "# Me-load full training MLP dan DTree\n",
    "clf_mlp = load_model(\"full_training_MLP_Iris.model\")\n",
    "clf_tree = load_model(\"full_training_Tree_Iris.model\")\n",
    "clf_mlp_2 = load_model(\"full_training_MLP_Tennis.model\")\n",
    "clf_tree_2 = load_model(\"full_training_Tree_Tennis.model\")\n",
    "\n",
    "# Tes apakah berhasil load dengan melakukan prediksi\n",
    "print(clf_mlp.predict(X_iris[:5]))\n",
    "print(clf_tree.predict(X_iris[:5]))\n",
    "print(clf_mlp_2.predict(X_tennis[:5]))\n",
    "print(clf_tree_2.predict(X_tennis[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C ANN + Decision Tree Split test\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix\n",
    "\n",
    "#Pisah data menjadi train dan test\n",
    "irisTrainX, irisTestX, irisTrainY, irisTestY =  train_test_split(X_iris, Y_iris, test_size=0.1, train_size=0.9)\n",
    "\n",
    "#Make Classifier\n",
    "decisionTree = tree.DecisionTreeClassifier()\n",
    "multiLayerANN = MLPClassifier(solver = \"lbfgs\")\n",
    "decisionTree.fit(irisTrainX, irisTrainY)\n",
    "multiLayerANN.fit(irisTrainX, irisTrainY)\n",
    "\n",
    "treePredict = decisionTree.predict(irisTestX)\n",
    "annPredict = multiLayerANN.predict(irisTestX)\n",
    "\n",
    "print(treePredict)\n",
    "treeAccuracy = accuracy_score(irisTestY, treePredict)\n",
    "treeMatrix = confusion_matrix(irisTestY, treePredict)\n",
    "print()\n",
    "print(\"Accuracy : \") \n",
    "print(treeAccuracy)\n",
    "print()\n",
    "print(\"Confusion Matrix :\")\n",
    "print(treeMatrix)\n",
    "print()\n",
    "\n",
    "print(annPredict)\n",
    "annAccuracy = accuracy_score(irisTestY, annPredict)\n",
    "annMatrix = confusion_matrix(irisTestY, annPredict)\n",
    "print()\n",
    "print(\"Accuracy : \") \n",
    "print(annAccuracy)\n",
    "print()\n",
    "print(\"Confusion Matrix :\")\n",
    "print(annMatrix)\n",
    "print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#D 10-fold Cross validation for decision tree and ANN\n",
    "from sklearn.model_selection import cross_val_score\n",
    "decisionTree = tree.DecisionTreeClassifier()\n",
    "multiLayerANN = MLPClassifier(solver = \"lbfgs\")\n",
    "\n",
    "treeCrossVal = cross_val_score(decisionTree, X_iris, Y_iris, cv=10)\n",
    "print(\"\\nTree Score :\")\n",
    "print(treeCrossVal)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (treeCrossVal.mean(), treeCrossVal.std() * 2))\n",
    "annCrossVal = cross_val_score(multiLayerANN, X_iris, Y_iris, cv=10)\n",
    "print(\"\\nANN Score :\")\n",
    "print(annCrossVal)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (annCrossVal.mean(), annCrossVal.std() * 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input attributes with float64  type\n",
      "1.2\n",
      "2.3\n",
      "4.1\n",
      "2.3\n",
      "Input attributes with int64  type\n",
      "5\n",
      "\n",
      "X =  [ 1.2  2.3  4.1  2.3]\n",
      "Y =  5\n"
     ]
    }
   ],
   "source": [
    "#G Create new instances\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "iris_dataset = datasets.load_iris()\n",
    "X_iris = iris_dataset.data\n",
    "Y_iris = iris_dataset.target\n",
    "\n",
    "X = []\n",
    "print(\"Input attributes with\", X_iris.dtype, \" type\") \n",
    "for i in range(0, len(X_iris[0])):\n",
    "    inp = input()\n",
    "    X.append(inp)\n",
    "\n",
    "X = np.array(X, dtype=X_iris.dtype)\n",
    "print(\"Input attributes with\", Y_iris.dtype, \" type\") \n",
    "Y = np.array(input(), dtype=Y_iris.dtype)\n",
    "\n",
    "print(\"\\nX = \", X)\n",
    "print(\"Y = \", Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
